{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import copy\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "from math import ceil\n",
    "from itertools import cycle\n",
    "from itertools import chain\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training start, 总共 80 epochs\n",
      "GPUs: cuda\n",
      "DeeplabV3+ with ResNet 101 backbone\n",
      "Current Labeled Example: 515\n",
      "Learning rate: other 0.01, and head is the SAME [world]\n",
      "Current batch: 16 [world]\n",
      "Current unsupervised loss function: semi_ce, with weight 1.5 and length 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "config json :\n",
      "name PS-MT(DeeplabV3+)\n",
      "experim_name TEST_warm\n",
      "n_labeled_examples 515\n",
      "ramp_up 12\n",
      "unsupervised_w 1.5\n",
      "lr_scheduler Poly\n",
      "gamma 0.5\n",
      "model {'supervised': False, 'semi': True, 'resnet': 101, 'sup_loss': 'DE', 'un_loss': 'semi_ce', 'epochs': 80, 'warm_up_epoch': 100, 'data_h_w': [224, 224]}\n",
      "optimizer {'type': 'SGD', 'args': {'lr': 0.01, 'weight_decay': 0.0001, 'momentum': 0.9}}\n",
      "train_supervised {'data_dir': 'FA', 'batch_size': 8, 'shuffle': True, 'crop_size': 224, 'split': 'train_supervised', 'num_workers': 8}\n",
      "train_unsupervised {'data_dir': 'range_unFA', 'batch_size': 8, 'shuffle': True, 'crop_size': 224, 'split': 'train_unsupervised', 'num_workers': 8}\n",
      "warm_selfsupervised {'data_dir': 'range_unFA', 'batch_size': 8, 'shuffle': True, 'crop_size': 224, 'split': 'train_unsupervised', 'num_workers': 8}\n",
      "val_loader {'data_dir': 'FA', 'batch_size': 1, 'split': 'val', 'shuffle': False, 'num_workers': 4}\n",
      "test_loader {'data_dir': 'FA', 'batch_size': 1, 'split': 'test', 'shuffle': False, 'num_workers': 4}\n"
     ]
    }
   ],
   "source": [
    "#config\n",
    "batch_size = 8\n",
    "epochs = 80\n",
    "warm_up = 100\n",
    "labeled_examples = 515\n",
    "lr = 1e-2\n",
    "backbone = 101 #\" the resnet x {50, 101} layers\"\n",
    "semi_p_th = 0.6 # positive_threshold for semi-supervised loss\n",
    "semi_n_th = 0.0 # negative_threshold for semi-supervised loss\n",
    "unsup_weight = 1.5 # unsupervised weight for the semi-supervised loss\n",
    "\n",
    "config = json.load(open(\"configs/config_deeplab_v3+_onlyFA_range_selfsupervised.json\"))\n",
    "\n",
    "config['train_supervised']['batch_size'] = batch_size\n",
    "config['train_unsupervised']['batch_size'] = batch_size\n",
    "config['warm_selfsupervised']['batch_size'] = batch_size\n",
    "config['model']['epochs'] = epochs\n",
    "config['model']['warm_up_epoch'] = warm_up\n",
    "config['n_labeled_examples'] = labeled_examples\n",
    "config['model']['resnet'] = backbone\n",
    "config['optimizer']['args']['lr'] = lr\n",
    "config['unsupervised_w'] = unsup_weight\n",
    "config['model']['data_h_w'] = [config['train_supervised']['crop_size'], config['train_supervised']['crop_size']]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "logger = logging.getLogger(\"PS-MT\")\n",
    "logger.propagate = False\n",
    "logger.warning(\"Training start, 总共 {} epochs\".format(str(config['model']['epochs'])))\n",
    "logger.critical(\"GPUs: {}\".format(device))\n",
    "logger.critical(\"DeeplabV3+ with ResNet {} backbone\".format(str(config['model']['resnet'])))\n",
    "logger.critical(\"Current Labeled Example: {}\".format(config['n_labeled_examples']))\n",
    "logger.critical(\"Learning rate: other {}, and head is the SAME [world]\".format(config['optimizer']['args']['lr']))\n",
    "\n",
    "logger.critical(\"Current batch: {} [world]\".format(int(config['train_unsupervised']['batch_size']) +\n",
    "                                                int(config['train_supervised']['batch_size'])) )\n",
    "\n",
    "logger.critical(\"Current unsupervised loss function: {}, with weight {} and length {}\".format(config['model']['un_loss'],\n",
    "                                                                                            config['unsupervised_w'],\n",
    "                                                                                            config['ramp_up']))\n",
    "print(\"\\nconfig json :\")\n",
    "for i in config:\n",
    "    print(i, config[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_supervised\n",
      "     data_dir : FA\n",
      "     batch_size : 8\n",
      "     shuffle : True\n",
      "     crop_size : 224\n",
      "     split : train_supervised\n",
      "     num_workers : 8\n",
      "     choose : All\n",
      "train_unsupervised\n",
      "     data_dir : range_unFA\n",
      "     batch_size : 8\n",
      "     shuffle : True\n",
      "     crop_size : 224\n",
      "     split : train_unsupervised\n",
      "     num_workers : 8\n",
      "     choose : All\n",
      "warm_selfsupervised\n",
      "     data_dir : range_unFA\n",
      "     batch_size : 8\n",
      "     shuffle : True\n",
      "     crop_size : 224\n",
      "     split : train_unsupervised\n",
      "     num_workers : 8\n",
      "     choose : All\n",
      "val_loader\n",
      "     data_dir : FA\n",
      "     batch_size : 1\n",
      "     split : val\n",
      "     shuffle : False\n",
      "     num_workers : 4\n",
      "     choose : All\n",
      "test_loader\n",
      "     data_dir : FA\n",
      "     batch_size : 1\n",
      "     split : test\n",
      "     shuffle : False\n",
      "     num_workers : 4\n",
      "     choose : All\n",
      "supervised_loader:  515\n",
      "unsupervised_loader:  5263\n",
      "warm_selfsupervised_loader:  5263\n",
      "val_loader:  162\n",
      "test_loader:  157\n"
     ]
    }
   ],
   "source": [
    "# DATA LOADERS\n",
    "from DataLoader.dataset_onlyFA import *\n",
    "choose_data = \"All\"\n",
    "\n",
    "config['train_supervised']['choose'] = choose_data\n",
    "config['train_unsupervised']['choose'] = choose_data\n",
    "config['warm_selfsupervised']['choose'] = choose_data\n",
    "config['val_loader']['choose'] = choose_data\n",
    "config['test_loader']['choose'] = choose_data\n",
    "\n",
    "print(\"train_supervised\")\n",
    "for i in config['train_supervised']:\n",
    "    print(\"    \",i, \":\", config['train_supervised'][i])\n",
    "print(\"train_unsupervised\")\n",
    "for i in config['train_unsupervised']:\n",
    "    print(\"    \", i, \":\", config['train_unsupervised'][i])\n",
    "print(\"warm_selfsupervised\")\n",
    "for i in config['warm_selfsupervised']:\n",
    "    print(\"    \", i, \":\", config['warm_selfsupervised'][i])\n",
    "print(\"val_loader\")\n",
    "for i in config['val_loader']:\n",
    "    print(\"    \", i, \":\", config['val_loader'][i])\n",
    "print(\"test_loader\")\n",
    "for i in config['test_loader']:\n",
    "    print(\"    \", i, \":\", config['test_loader'][i])\n",
    "\n",
    "supervised_set = BasicDataset(data_dir=config['train_supervised']['data_dir'], \n",
    "                                 choose=config['train_supervised']['choose'],\n",
    "                                 split=config['train_supervised']['split'])\n",
    "\n",
    "unsupervised_set = BasicDataset(data_dir=config['train_unsupervised']['data_dir'],\n",
    "                                   choose=config['train_unsupervised']['choose'],\n",
    "                                   split=config['train_unsupervised']['split'])\n",
    "\n",
    "warm_selfsupervised_set = BasicDataset(data_dir=config['warm_selfsupervised']['data_dir'],\n",
    "                                      choose=config['warm_selfsupervised']['choose'],\n",
    "                                      split=config['warm_selfsupervised']['split'])\n",
    "\n",
    "val_set = BasicDataset(data_dir=config['val_loader']['data_dir'],\n",
    "                          choose=config['val_loader']['choose'],\n",
    "                          split=config['val_loader']['split'])\n",
    "\n",
    "test_set = BasicDataset(data_dir=config['test_loader']['data_dir'],\n",
    "                          choose=config['test_loader']['choose'],\n",
    "                          split=config['test_loader']['split'])\n",
    "\n",
    "print(\"supervised_loader: \",len(supervised_set))\n",
    "print(\"unsupervised_loader: \",len(unsupervised_set))\n",
    "print(\"warm_selfsupervised_loader: \",len(warm_selfsupervised_set))\n",
    "print(\"val_loader: \",len(val_set))\n",
    "print(\"test_loader: \",len(test_set))\n",
    "\n",
    "\n",
    "supervised_loader = DataLoader(dataset=supervised_set, batch_size=config['train_supervised']['batch_size'],\n",
    "                               shuffle=config['train_supervised']['shuffle'], \n",
    "                               num_workers=config['train_supervised']['num_workers'])\n",
    "\n",
    "unsupervised_loader = DataLoader(dataset=unsupervised_set, batch_size=config['train_unsupervised']['batch_size'],\n",
    "                               shuffle=config['train_unsupervised']['shuffle'], \n",
    "                               num_workers=config['train_unsupervised']['num_workers'])\n",
    "                               \n",
    "warm_selfsupervised_loader = DataLoader(dataset=unsupervised_set, batch_size=config['warm_selfsupervised']['batch_size'],\n",
    "                              shuffle=config['warm_selfsupervised']['shuffle'],\n",
    "                              num_workers=config['warm_selfsupervised']['num_workers'])\n",
    "\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=config['val_loader']['batch_size'],\n",
    "                               shuffle=config['val_loader']['shuffle'], \n",
    "                               num_workers=config['val_loader']['num_workers'])\n",
    "\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=config['test_loader']['batch_size'],\n",
    "                               shuffle=config['test_loader']['shuffle'], \n",
    "                               num_workers=config['test_loader']['num_workers'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate metrics\n",
    "from sklearn import metrics, neighbors\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#compute mean IoU & DSC  of given outputs & targets per patient (5 time points)\n",
    "def information_index(outputs, targets):\n",
    "    eps = np.finfo(np.float64).eps\n",
    "    output = outputs.flatten()\n",
    "    target = targets.flatten()\n",
    "    \n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(target, output).ravel()\n",
    "    \n",
    "    # Handle different shapes of confusion matrix\n",
    "    if len(cm) == 4:\n",
    "        TN, FP, FN, TP = cm\n",
    "    elif len(cm) == 1:\n",
    "        # Case where only one class is present in both target and output\n",
    "        if target[0] == 0:\n",
    "            TN, FP, FN, TP = cm[0], 0, 0, 0  # All True Negatives\n",
    "        else:\n",
    "            TN, FP, FN, TP = 0, 0, 0, cm[0]  # All True Positives\n",
    "    elif len(cm) == 2:\n",
    "        # Case where target and output contain only a single class\n",
    "        if target[0] == 0:\n",
    "            TN, FP, FN, TP = cm[0], cm[1], 0, 0  # No False Negatives or True Positives\n",
    "        else:\n",
    "            TN, FP, FN, TP = 0, 0, cm[0], cm[1]  # No True Negatives or False Positives\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected confusion matrix size.\")\n",
    "\n",
    "    # Compute IoU and Dice coefficients\n",
    "    index_MIou = (TP / (TP + FP + FN + eps) + TN / (TN + FN + FP + eps)) / 2\n",
    "    mean_iou = np.mean(index_MIou)\n",
    "    index_dice = 2 * TP / (2 * TP + FP + FN + eps)\n",
    "    mean_dice = np.mean(index_dice)\n",
    "\n",
    "    return mean_iou, mean_dice\n",
    "#compute mean IoU & DSC of validaton (test set)\n",
    "def count_index(pre, tar):\n",
    "        path_pre = pre\n",
    "        path_target = tar\n",
    "        dirs = os.listdir(path_pre)\n",
    "        # print(len(dirs))\n",
    "        con_mIOU = 0\n",
    "        con_mdice = 0\n",
    "        for imgs in dirs:\n",
    "            pre_path = path_pre + '/' + str(imgs)\n",
    "            target_path = path_target + '/' + str(imgs)\n",
    "\n",
    "            target = cv2.imread(target_path, cv2.IMREAD_GRAYSCALE)\n",
    "            _, tar = cv2.threshold(target, 128, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "            predict = cv2.imread(pre_path, cv2.IMREAD_GRAYSCALE)\n",
    "            _, pre = cv2.threshold(predict, 128, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "            tIOU, tdice = information_index(pre,tar)\n",
    "            con_mIOU += tIOU\n",
    "            con_mdice += tdice\n",
    "        val_mIoU = con_mIOU/len(dirs)\n",
    "        val_mDice = con_mdice/len(dirs)\n",
    "        \n",
    "        return val_mIoU, val_mDice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate DSC & HD\n",
    "\n",
    "from medpy import metric\n",
    "\n",
    "#calculate DSC & HD of each image\n",
    "def calculate_metric_percase(pred, gt):\n",
    "    pred[pred > 0] = 1\n",
    "    gt[gt > 0] = 1\n",
    "    if pred.sum() > 0:\n",
    "        dice = metric.binary.dc(pred, gt)\n",
    "        hd95 = metric.binary.hd95(pred, gt)\n",
    "        return dice, hd95\n",
    "    else:\n",
    "        return 0, 0\n",
    "\n",
    "#append DSC & HD of each patient (5 time points)\n",
    "def test_single_volume(label, output, classes=2):\n",
    "    label = torch.clamp(label, 0, 1)\n",
    "    label = label.squeeze(0).cpu().detach().numpy()\n",
    "    output = output.cpu().detach().numpy()\n",
    "    metric_list = []\n",
    "    for i in range(1, classes):\n",
    "        metric_list.append(calculate_metric_percase(\n",
    "            output == i, label == i))\n",
    "    \n",
    "    return metric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model setting (1 teacher + 1 student)\n",
    "from torch import optim\n",
    "\n",
    "from Model.selfsupervised.selfsupervised_model import *\n",
    "from Utils.ramps import *\n",
    "\n",
    "cons_w_unsup = ConsistencyWeight(final_w=config['unsupervised_w'], iters_per_epoch=len(unsupervised_loader),\n",
    "                                 rampup_starts=0, rampup_ends=config['ramp_up'],  ramp_type=\"cosine_rampup\")\n",
    "\n",
    "\n",
    "model_t1 = Teacher_Net(num_classes=2, config=config['model'])\n",
    "model_t1 = model_t1.to(device)\n",
    "\n",
    "model_s = Student_Net(num_classes=2, config=config['model'],  cons_w_unsup=cons_w_unsup)\n",
    "model_s = model_s.to(device)\n",
    "\n",
    "optimizer_t1 = optim.SGD(model_t1.parameters(), \n",
    "                      lr=config['optimizer']['args']['lr'],\n",
    "                      momentum=config['optimizer']['args']['momentum'],\n",
    "                      weight_decay=config['optimizer']['args']['weight_decay'])\n",
    "\n",
    "optimizer_s = optim.SGD(model_s.parameters(), \n",
    "                      lr=config['optimizer']['args']['lr'],\n",
    "                      momentum=config['optimizer']['args']['momentum'],\n",
    "                      weight_decay=config['optimizer']['args']['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:03<00:00, 45.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73.82377664290077, 51.19863204015901, 104.4877954824302, 165.66577766554886, 54.037024344425184, 27.582598675073818, 58.75794352136386, 36.05551275463989, 29.17532117774409, 73.12591450262427, 36.235341863986875, 56.00535586144822, 34.9828507202755, 45.55764686119848, 61.08511747271744, 69.11946170882587, 106.16025245284726, 48.30113870293329, 102.94950174442525, 46.87216658103186, 26.832815729997478, 86.34002473492443, 90.77306615441785, 55.323141463735, 29.154759474226502, 52.0, 76.02631123499285, 112.90438315871492, 33.19629283530026, 55.98258213080535, 60.452433948779344, 67.4166151627327, 36.069377593742864, 33.06055050963308, 30.610455730027933, 39.59797974644666, 32.55764119219941, 150.40810957816836, 48.507731342539614, 26.970329614269, 86.58059163133099, 149.10566697511024, 49.768402284594885, 86.01045769134377, 105.4324425047794, 36.345563690772494, 27.65863337187866, 36.134470520342774, 75.13421311940617, 66.89088722214798, 67.18333116708747, 86.78565115969761, 72.94518489934754, 26.46506159724712, 29.349466757699943, 81.97101609593427, 45.05985459095385, 26.641693216072717, 140.80127840328723, 17.08800749063506, 76.54149178163243, 30.479501308256342, 73.7426913689368, 42.43760117401324, 42.09750157220891, 44.05677570135235, 18.0, 60.207972893961475, 49.193495504995376, 51.02597168212698, 25.55972790549828, 68.3589789088349, 72.4592981882841, 24.0, 109.42484031276534, 35.35533905932738, 61.58488714042463, 58.830262479120385, 57.100756332539675, 41.048751503547585, 60.02582668186317, 118.16069339584507, 141.43107834795688, 58.77070775297327, 17.08800749063506, 32.23041234640021, 71.24954506327994, 73.0, 101.46672151262672, 71.06335201775947, 100.01174903143338, 27.65863337187866, 41.61068573997027, 45.69463863518345, 55.0, 87.72105947531324, 99.25069212912734, 67.26812023536856, 126.13484822659616, 96.67857750626933, 36.29252951727865, 48.75448697299562, 57.42036947102792, 58.96946518715267, 73.03560359950885, 55.54277630799526, 71.11258679024411, 59.62674663282035, 125.49699564021454, 44.65086755780238, 24.807225540561017, 63.740035952397996, 33.015148038438355, 44.22889983429672, 61.09828148156051, 64.4980619863884, 69.07025241764622, 26.0, 21.02379604162864, 111.98883852936441, 112.6729769941805, 21.93171219946131, 62.384291782755874, 37.013511046643494, 16.17399334760795, 74.6149972203185, 51.62363799656123, 30.877984634808893, 72.61817855040675, 50.99019513592785, 51.54609587543949, 67.41735677887445, 81.23237873982609, 23.466911968137403, 150.26925028095823, 41.10048087039272, 61.39381067655365, 75.00433314075785, 123.71337841963576, 38.07886552931954, 45.31004303683677, 76.69322000399035, 33.0, 110.9414259868693, 24.698178070456937, 73.7597450409916, 70.52798389871897, 73.48330960006243, 107.97800029653791, 93.4751141800821, 27.152328013454667, 86.74819074637452, 61.71385505247055, 169.82638152333269, 37.19609915697368, 148.8099385432294, 34.62651605368281, 65.52098900352466, 104.79932774525977, 39.0, 89.11789095509283, 25.008989225842505]\n",
      "original_models valiation : HD95 = 63.3680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# val HD\n",
    "\n",
    "PRED_MODEL_t1 = './saved_models/original_models/original_epoch_2_dsc_0.2770_best_t1.pth'\n",
    "PRED_MODEL_s = './saved_models//original_models/original_epoch_2_dsc_0.2770_best_s.pth'\n",
    "\n",
    "model_t1.load_state_dict(torch.load(PRED_MODEL_t1, map_location=device))\n",
    "model_s.load_state_dict(torch.load(PRED_MODEL_s, map_location=device))\n",
    "\n",
    "folder_name = None\n",
    "folder_name = os.path.join(\"see_image\")\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# validation\n",
    "metric_list = 0.0\n",
    "list = []\n",
    "model_t1.eval()\n",
    "model_s.eval()\n",
    "for batch in tqdm(val_loader):\n",
    "    image_val, label, id_val = batch\n",
    "    image_val, label, id_val = image_val.to(device), label.to(device), id_val\n",
    "\n",
    "    H, W = label.size(1), label.size(2)\n",
    "    up_sizes = (ceil(H / 8) * 8, ceil(W / 8) * 8)\n",
    "    data = torch.nn.functional.interpolate(image_val, size=(up_sizes[0], up_sizes[1]),\n",
    "                                            mode='bilinear', align_corners=True)\n",
    "    with torch.no_grad():\n",
    "        loss_t1, output = model_t1(input_ul=data, target_ul=label)\n",
    "    output = torch.nn.functional.interpolate(output, size=(H, W),\n",
    "                                                mode='bilinear', align_corners=True)\n",
    "    \n",
    "    out = torch.argmax(torch.softmax(output, dim=1), dim=1).squeeze(0)\n",
    "    metric_i = test_single_volume(label, out, classes=2)\n",
    "    list.append(metric_i[0][1])\n",
    "    metric_list += np.array(metric_i)\n",
    "metric_list = metric_list / len(val_set)\n",
    "print(list)\n",
    "# index_mDice = np.mean(metric_list, axis=0)[0]\n",
    "index_mean_hd95 = np.mean(metric_list, axis=0)[1]\n",
    "\n",
    "\n",
    "\n",
    "# show the best HD\n",
    "print(\"original_models valiation : \" + f'HD95 = {index_mean_hd95:.4f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 46.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSC = 0.3011820534715776, HD95 = 58.47744415479772\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "model_t1.eval()\n",
    "model_s.eval()\n",
    "for batch in tqdm(test_loader):\n",
    "    image_test, label, id_test = batch\n",
    "    image_test, label, id_test = image_test.to(device), label.to(device), id_test\n",
    "\n",
    "    H, W = label.size(1), label.size(2)\n",
    "    up_sizes = (ceil(H / 8) * 8, ceil(W / 8) * 8)\n",
    "\n",
    "    for i in range(0, int(label.size(0))):\n",
    "        folder_test = os.path.join(folder_name, \"test_target\")\n",
    "        os.makedirs(folder_test, exist_ok=True)\n",
    "        image = Image.fromarray(np.uint8(label[i].detach().cpu().numpy()))\n",
    "        image.save(os.path.join(folder_test, str(id_test[i]) + \".png\"))\n",
    "\n",
    "    data = torch.nn.functional.interpolate(image_test, size=(up_sizes[0], up_sizes[1]),\n",
    "                                            mode='bilinear', align_corners=True)\n",
    "    with torch.no_grad():\n",
    "         loss_t1, output = model_t1(input_ul=data,  target_ul=label)\n",
    "    output = torch.nn.functional.interpolate(output, size=(H, W),\n",
    "                                                mode='bilinear', align_corners=True)\n",
    "\n",
    "    for i in range(0, int(output.size(0))):\n",
    "        folder_test_prob = os.path.join(folder_name, \"test_original_models_prob\")\n",
    "        os.makedirs(folder_test_prob, exist_ok=True)\n",
    "        image_prob = output[i].squeeze().detach()\n",
    "        image_prob = torch.argmax(image_prob, dim=0).cpu().numpy()\n",
    "        image_prob = Image.fromarray((image_prob * 255).astype(np.uint8))\n",
    "        image_prob.save(os.path.join(folder_test_prob, str(id_test[i]) + \".png\"))\n",
    "\n",
    "    out = torch.argmax(torch.softmax(output, dim=1), dim=1).squeeze(0)\n",
    "    metric_i = test_single_volume(label, out, classes=2)\n",
    "    metric_list += np.array(metric_i)\n",
    "metric_list = metric_list / len(test_set)\n",
    "\n",
    "# performance = np.mean(metric_list, axis=0)[0]\n",
    "\n",
    "mean_hd95 = np.mean(metric_list, axis=0)[1]\n",
    "\n",
    "# show epoch mIoU, mDice\n",
    "index_mIoU, index_mDice = count_index(folder_test_prob, folder_test)\n",
    "\n",
    "\n",
    "print(f'DSC = {index_mDice}, HD95 = {mean_hd95}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
