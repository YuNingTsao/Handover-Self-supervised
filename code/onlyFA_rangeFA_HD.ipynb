{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mutil Mean Teacher\n",
    "\n",
    "original\n",
    "FAICG_FA_FA\n",
    "\n",
    "backbone=DeeplabV3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import copy\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "from math import ceil\n",
    "from itertools import cycle\n",
    "from itertools import chain\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training start, 总共 80 epochs\n",
      "GPUs: cuda\n",
      "DeeplabV3+ with ResNet 101 backbone\n",
      "Current Labeled Example: 515\n",
      "Learning rate: other 0.01, and head is the SAME [world]\n",
      "Current batch: 16 [world]\n",
      "Current unsupervised loss function: semi_ce, with weight 1.5 and length 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "config json :\n",
      "name PS-MT(DeeplabV3+)\n",
      "experim_name TEST_warm\n",
      "n_labeled_examples 515\n",
      "ramp_up 12\n",
      "unsupervised_w 1.5\n",
      "lr_scheduler Poly\n",
      "gamma 0.5\n",
      "model {'supervised': False, 'semi': True, 'resnet': 101, 'sup_loss': 'DE', 'un_loss': 'semi_ce', 'epochs': 80, 'warm_up_epoch': 100, 'data_h_w': [224, 224]}\n",
      "optimizer {'type': 'SGD', 'args': {'lr': 0.01, 'weight_decay': 0.0001, 'momentum': 0.9}}\n",
      "train_supervised {'data_dir': 'FA', 'batch_size': 8, 'shuffle': True, 'crop_size': 224, 'split': 'train_supervised', 'num_workers': 8}\n",
      "train_unsupervised {'data_dir': 'range_unFA', 'batch_size': 8, 'shuffle': True, 'crop_size': 224, 'split': 'train_unsupervised', 'num_workers': 8}\n",
      "val_loader {'data_dir': 'FA', 'batch_size': 1, 'split': 'val', 'shuffle': False, 'num_workers': 4}\n",
      "test_loader {'data_dir': 'FA', 'batch_size': 1, 'split': 'test', 'shuffle': False, 'num_workers': 4}\n"
     ]
    }
   ],
   "source": [
    "#config\n",
    "batch_size = 8\n",
    "epochs = 80\n",
    "warm_up = 100\n",
    "labeled_examples = 515\n",
    "lr = 1e-2\n",
    "backbone = 101 #\" the resnet x {50, 101} layers\"\n",
    "semi_p_th = 0.6 # positive_threshold for semi-supervised loss\n",
    "semi_n_th = 0.0 # negative_threshold for semi-supervised loss\n",
    "unsup_weight = 1.5 # unsupervised weight for the semi-supervised loss\n",
    "\n",
    "config = json.load(open(\"configs/config_deeplab_v3+_onlyFA_range.json\"))\n",
    "\n",
    "config['train_supervised']['batch_size'] = batch_size\n",
    "config['train_unsupervised']['batch_size'] = batch_size\n",
    "config['model']['epochs'] = epochs\n",
    "config['model']['warm_up_epoch'] = warm_up\n",
    "config['n_labeled_examples'] = labeled_examples\n",
    "config['model']['resnet'] = backbone\n",
    "config['optimizer']['args']['lr'] = lr\n",
    "config['unsupervised_w'] = unsup_weight\n",
    "config['model']['data_h_w'] = [config['train_supervised']['crop_size'], config['train_supervised']['crop_size']]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "logger = logging.getLogger(\"PS-MT\")\n",
    "logger.propagate = False\n",
    "logger.warning(\"Training start, 总共 {} epochs\".format(str(config['model']['epochs'])))\n",
    "logger.critical(\"GPUs: {}\".format(device))\n",
    "logger.critical(\"DeeplabV3+ with ResNet {} backbone\".format(str(config['model']['resnet'])))\n",
    "logger.critical(\"Current Labeled Example: {}\".format(config['n_labeled_examples']))\n",
    "logger.critical(\"Learning rate: other {}, and head is the SAME [world]\".format(config['optimizer']['args']['lr']))\n",
    "\n",
    "logger.critical(\"Current batch: {} [world]\".format(int(config['train_unsupervised']['batch_size']) +\n",
    "                                                int(config['train_supervised']['batch_size'])) )\n",
    "\n",
    "logger.critical(\"Current unsupervised loss function: {}, with weight {} and length {}\".format(config['model']['un_loss'],\n",
    "                                                                                            config['unsupervised_w'],\n",
    "                                                                                            config['ramp_up']))\n",
    "print(\"\\nconfig json :\")\n",
    "for i in config:\n",
    "    print(i, config[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_supervised\n",
      "     data_dir : FA\n",
      "     batch_size : 8\n",
      "     shuffle : True\n",
      "     crop_size : 224\n",
      "     split : train_supervised\n",
      "     num_workers : 8\n",
      "     choose : All\n",
      "train_unsupervised\n",
      "     data_dir : range_unFA\n",
      "     batch_size : 8\n",
      "     shuffle : True\n",
      "     crop_size : 224\n",
      "     split : train_unsupervised\n",
      "     num_workers : 8\n",
      "     choose : All\n",
      "val_loader\n",
      "     data_dir : FA\n",
      "     batch_size : 1\n",
      "     split : val\n",
      "     shuffle : False\n",
      "     num_workers : 4\n",
      "     choose : All\n",
      "test_loader\n",
      "     data_dir : FA\n",
      "     batch_size : 1\n",
      "     split : test\n",
      "     shuffle : False\n",
      "     num_workers : 4\n",
      "     choose : All\n",
      "supervised_loader:  515\n",
      "unsupervised_loader:  5263\n",
      "val_loader:  162\n",
      "test_loader:  157\n"
     ]
    }
   ],
   "source": [
    "# DATA LOADERS\n",
    "from DataLoader.dataset_onlyFA import *\n",
    "choose_data = \"All\"\n",
    "\n",
    "config['train_supervised']['choose'] = choose_data\n",
    "config['train_unsupervised']['choose'] = choose_data\n",
    "config['val_loader']['choose'] = choose_data\n",
    "config['test_loader']['choose'] = choose_data\n",
    "\n",
    "print(\"train_supervised\")\n",
    "for i in config['train_supervised']:\n",
    "    print(\"    \",i, \":\", config['train_supervised'][i])\n",
    "print(\"train_unsupervised\")\n",
    "for i in config['train_unsupervised']:\n",
    "    print(\"    \", i, \":\", config['train_unsupervised'][i])\n",
    "print(\"val_loader\")\n",
    "for i in config['val_loader']:\n",
    "    print(\"    \", i, \":\", config['val_loader'][i])\n",
    "print(\"test_loader\")\n",
    "for i in config['test_loader']:\n",
    "    print(\"    \", i, \":\", config['test_loader'][i])\n",
    "\n",
    "supervised_set = BasicDataset(data_dir=config['train_supervised']['data_dir'], \n",
    "                                 choose=config['train_supervised']['choose'],\n",
    "                                 split=config['train_supervised']['split'])\n",
    "unsupervised_set = BasicDataset(data_dir=config['train_unsupervised']['data_dir'],\n",
    "                                   choose=config['train_unsupervised']['choose'],\n",
    "                                   split=config['train_unsupervised']['split'])\n",
    "val_set = BasicDataset(data_dir=config['val_loader']['data_dir'],\n",
    "                          choose=config['val_loader']['choose'],\n",
    "                          split=config['val_loader']['split'])\n",
    "\n",
    "test_set = BasicDataset(data_dir=config['test_loader']['data_dir'],\n",
    "                          choose=config['test_loader']['choose'],\n",
    "                          split=config['test_loader']['split'])\n",
    "\n",
    "self_supervised_set = BasicDataset(data_dir=config['tain_unsupervised']['data_dir'],\n",
    "                                    choose=config['train_unsupervised']['choose'],\n",
    "                                    split=cofig=['train_unsupervised']['split'])\n",
    "\n",
    "print(\"supervised_loader: \",len(supervised_set))\n",
    "print(\"unsupervised_loader: \",len(unsupervised_set))\n",
    "print(\"val_loader: \",len(val_set))\n",
    "print(\"test_loader: \",len(test_set))\n",
    "\n",
    "\n",
    "supervised_loader = DataLoader(dataset=supervised_set, batch_size=config['train_supervised']['batch_size'],\n",
    "                               shuffle=config['train_supervised']['shuffle'], \n",
    "                               num_workers=config['train_supervised']['num_workers'])\n",
    "unsupervised_loader = DataLoader(dataset=unsupervised_set, batch_size=config['train_unsupervised']['batch_size'],\n",
    "                               shuffle=config['train_unsupervised']['shuffle'], \n",
    "                               num_workers=config['train_unsupervised']['num_workers'])\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=config['val_loader']['batch_size'],\n",
    "                               shuffle=config['val_loader']['shuffle'], \n",
    "                               num_workers=config['val_loader']['num_workers'])\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=config['test_loader']['batch_size'],\n",
    "                               shuffle=config['test_loader']['shuffle'], \n",
    "                               num_workers=config['test_loader']['num_workers'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate metrics \n",
    "\n",
    "from sklearn import metrics, neighbors\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#calculate mean IoU & mean DSC of given outputs & targets\n",
    "def information_index(outputs, targets):\n",
    "    eps = np.finfo(np.float64).eps\n",
    "    output = outputs.flatten()\n",
    "    target = targets.flatten()\n",
    "    TN, FP, FN, TP = confusion_matrix(target,output).ravel()\n",
    "\n",
    "    index_MIou =  ( TP / (TP + FP + FN + eps) + TN / (TN + FN + FP + eps) ) / 2\n",
    "    mean_iou = np.mean(index_MIou)\n",
    "    index_dice = 2*TP / (2*TP + FP + FN + eps)\n",
    "    mean_dice = np.mean(index_dice)\n",
    "\n",
    "    return mean_iou, mean_dice\n",
    "\n",
    "#calculate mean IoU & mean DSC of validation (test set)\n",
    "def count_index(pre, tar):\n",
    "        path_pre = pre\n",
    "        path_target = tar\n",
    "        dirs = os.listdir(path_pre)\n",
    "        # print(len(dirs))\n",
    "        con_mIOU = 0\n",
    "        con_mdice = 0\n",
    "        for imgs in dirs:\n",
    "            pre_path = path_pre + '/' + str(imgs)\n",
    "            target_path = path_target + '/' + str(imgs)\n",
    "\n",
    "            target = cv2.imread(target_path, cv2.IMREAD_GRAYSCALE)\n",
    "            _, tar = cv2.threshold(target, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            predict = cv2.imread(pre_path, cv2.IMREAD_GRAYSCALE)\n",
    "            _, pre = cv2.threshold(predict, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            tIOU, tdice = information_index(pre,tar)\n",
    "            con_mIOU += tIOU\n",
    "            con_mdice += tdice\n",
    "        val_mIoU = con_mIOU/len(dirs)\n",
    "        val_mDice = con_mdice/len(dirs)\n",
    "        \n",
    "        return val_mIoU, val_mDice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate DSC & HD\n",
    "\n",
    "from medpy import metric\n",
    "\n",
    "#calculate DSC & HD of each image\n",
    "def calculate_metric_percase(pred, gt):\n",
    "    pred[pred > 0] = 1\n",
    "    gt[gt > 0] = 1\n",
    "    if pred.sum() > 0:\n",
    "        dice = metric.binary.dc(pred, gt)\n",
    "        hd95 = metric.binary.hd95(pred, gt)\n",
    "        return dice, hd95\n",
    "    else:\n",
    "        return 0, 0\n",
    "\n",
    "#append DSC & HD of each patient (5 time points)\n",
    "def test_single_volume(label, output, classes=2):\n",
    "    label = torch.clamp(label, 0, 1)\n",
    "    label = label.squeeze(0).cpu().detach().numpy()\n",
    "    output = output.cpu().detach().numpy()\n",
    "    metric_list = []\n",
    "    for i in range(1, classes):\n",
    "        metric_list.append(calculate_metric_percase(\n",
    "            output == i, label == i))\n",
    "    \n",
    "    return metric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model, Time usage:\n",
      "\tIO: 0.07735347747802734, initialize parameters: 0.06389641761779785\n"
     ]
    }
   ],
   "source": [
    "#model setting (1 teacher + 1 student)\n",
    "from torch import optim\n",
    "\n",
    "from Model.semi_FAcrossICG.psmt_model import *\n",
    "from Utils.ramps import *\n",
    "\n",
    "cons_w_unsup = ConsistencyWeight(final_w=config['unsupervised_w'], iters_per_epoch=len(unsupervised_loader),\n",
    "                                 rampup_starts=0, rampup_ends=config['ramp_up'],  ramp_type=\"cosine_rampup\")\n",
    "\n",
    "\n",
    "model_t1 = Teacher_Net(num_classes=2, config=config['model'])\n",
    "model_t1 = model_t1.to(device)\n",
    "\n",
    "model_s = Student_Net(num_classes=2, config=config['model'],  cons_w_unsup=cons_w_unsup)\n",
    "model_s = model_s.to(device)\n",
    "\n",
    "optimizer_t1 = optim.SGD(model_t1.parameters(), \n",
    "                      lr=config['optimizer']['args']['lr'],\n",
    "                      momentum=config['optimizer']['args']['momentum'],\n",
    "                      weight_decay=config['optimizer']['args']['weight_decay'])\n",
    "\n",
    "optimizer_s = optim.SGD(model_s.parameters(), \n",
    "                      lr=config['optimizer']['args']['lr'],\n",
    "                      momentum=config['optimizer']['args']['momentum'],\n",
    "                      weight_decay=config['optimizer']['args']['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output prediction (not used ?)\n",
    "\n",
    "def predict_with_out_grad(model_t1, model_t2, image):\n",
    "    with torch.no_grad():\n",
    "        f = model_t1.encoder(image)\n",
    "        _, predict_target_ul1 = model_t1.decoder(f, data_shape=[image.shape[-2], image.shape[-1]])\n",
    "        f = model_t2.encoder(image)\n",
    "        _, predict_target_ul2 = model_t2.decoder(f, data_shape=[image.shape[-2], image.shape[-1]])\n",
    "        \n",
    "        predict_target_ul1 = torch.nn.functional.interpolate(predict_target_ul1,\n",
    "                                                                size=(image.shape[-2], image.shape[-1]),\n",
    "                                                                mode='bilinear',\n",
    "                                                                align_corners=True)\n",
    "\n",
    "        predict_target_ul2 = torch.nn.functional.interpolate(predict_target_ul2,\n",
    "                                                                size=(image.shape[-2], image.shape[-1]),\n",
    "                                                                mode='bilinear',\n",
    "                                                                align_corners=True)\n",
    "\n",
    "        assert predict_target_ul1.shape == predict_target_ul2.shape, \"Expect two prediction in same shape,\"\n",
    "    return predict_target_ul1, predict_target_ul2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:05<00:00, 27.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53.07354702367828, 22.012493550049882, 116.22404311194441, 50.30896258067844, 31.536538656821985, 19.1049731745428, 16.499967226201765, 18.675962833865334, 17.960777608553403, 65.38764115908302, 20.54969310597315, 67.06191131641506, 32.02732566131388, 52.51172637144293, 11.187008318073238, 70.45033329186475, 52.596379915298634, 29.111821590861886, 121.95469844753441, 15.620499351813308, 7.0, 38.43955450409533, 86.19826342205434, 0, 7.0, 14.5553641954947, 27.16615541441225, 20.223748416156685, 66.10899932542954, 87.40357078591929, 28.01249601657066, 16.1245154965971, 58.94890980364733, 25.495097567963924, 9.439266316901454, 20.500613895066955, 51.24451190127583, 136.98191266546922, 35.686259277859165, 7.654668419872456, 38.47466652927619, 131.739829138545, 15.696502859009138, 31.927819893644767, 18.661425078636622, 16.13071128155838, 24.515301344262525, 16.41884110129593, 17.46424919657298, 42.0, 36.251217941794195, 16.0, 15.795497055007555, 9.219544457292887, 15.842701020417424, 14.422205101855956, 43.18159294764197, 31.387895109603377, 132.89844597702145, 17.46424919657298, 27.834826305755822, 16.515056673664027, 21.0, 29.89508729361922, 20.517344861970244, 14.380451486424114, 40.06731121667125, 12.0, 17.75997842082917, 14.800259050713183, 7.014213562373095, 54.12254361905679, 56.156157624389444, 9.989949493661165, 104.76640422054645, 68.39148607345516, 17.3513766847916, 12.206555615733702, 30.0, 46.08307430886128, 48.79549159502341, 125.52097647098522, 142.35304498694526, 19.026297590440446, 21.195515934211926, 18.01942946412396, 36.201489911306325, 39.02045915678252, 17.88854381999832, 34.452088675443854, 21.0, 12.727922061357855, 27.0, 17.08800749063506, 107.75759097462107, 92.40236993022441, 30.85669051199314, 29.206163733020468, 21.940826679716846, 82.20851852224159, 15.915124735378845, 15.568289916344368, 50.00949905018995, 15.02164264594239, 32.54074010050939, 16.030107565777364, 20.06211418282915, 20.607034381948296, 14.083578896868936, 17.93494396795236, 25.99615099714943, 54.52681033337142, 18.439088914585774, 20.396078054371138, 0, 24.425260832992638, 33.465899687641645, 6.324555320336759, 10.346266869760246, 27.5010710068592, 45.53552609678528, 18.41445284899216, 26.51218493574698, 19.66213257414961, 21.303598625555956, 52.3302006042589, 16.9288010093541, 8.0, 55.06632034264173, 54.08326913195984, 51.85212022244331, 41.0091260281974, 67.0599787750532, 37.022955005035044, 125.7179382586272, 50.17761429440708, 70.02880999771875, 28.600699292150182, 158.15083846962364, 17.0, 18.483292224201634, 26.671119711213933, 17.0, 45.511514902634424, 10.256593695466425, 17.0, 52.80772745391688, 17.08800749063506, 6.535562057026199, 5.873213921133976, 5.0, 37.20617155732523, 26.91282087660495, 13.746957249092624, 20.248456731316587, 134.43584822210403, 18.12582417456235, 76.0460284403944, 19.045884928453166, 62.8408757517181, 116.98280389476805, 9.45776446385844]\n",
      "original_models valiation : HD95 = 37.2838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# val HD\n",
    "\n",
    "PRED_MODEL_t1 = './saved_models/onlyFA_rangeFA/original_models/original_epoch_3_dsc_0.5765_best_t1.pth'\n",
    "PRED_MODEL_s = './saved_models//onlyFA_rangeFA/original_models/original_epoch_3_dsc_0.5765_best_s.pth'\n",
    "\n",
    "model_t1.load_state_dict(torch.load(PRED_MODEL_t1, map_location=device))\n",
    "model_s.load_state_dict(torch.load(PRED_MODEL_s, map_location=device))\n",
    "\n",
    "folder_name = None\n",
    "folder_name = os.path.join(\"see_image\")\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# validation\n",
    "metric_list = 0.0\n",
    "list = []\n",
    "model_t1.eval()\n",
    "model_s.eval()\n",
    "for batch in tqdm(val_loader):\n",
    "    image_val, label, id_val = batch\n",
    "    image_val, label, id_val = image_val.to(device), label.to(device), id_val\n",
    "\n",
    "    H, W = label.size(1), label.size(2)\n",
    "    up_sizes = (ceil(H / 8) * 8, ceil(W / 8) * 8)\n",
    "    data = torch.nn.functional.interpolate(image_val, size=(up_sizes[0], up_sizes[1]),\n",
    "                                            mode='bilinear', align_corners=True)\n",
    "    with torch.no_grad():\n",
    "        f = model_t1.encoder(data)\n",
    "        _, output = model_t1.decoder(f, data_shape=[data.shape[-2], data.shape[-1]])\n",
    "    output = torch.nn.functional.interpolate(output, size=(H, W),\n",
    "                                                mode='bilinear', align_corners=True)\n",
    "    \n",
    "    out = torch.argmax(torch.softmax(output, dim=1), dim=1).squeeze(0)\n",
    "    metric_i = test_single_volume(label, out, classes=2)\n",
    "    list.append(metric_i[0][1])\n",
    "    metric_list += np.array(metric_i)\n",
    "metric_list = metric_list / len(val_set)\n",
    "print(list)\n",
    "# index_mDice = np.mean(metric_list, axis=0)[0]\n",
    "index_mean_hd95 = np.mean(metric_list, axis=0)[1]\n",
    "\n",
    "\n",
    "\n",
    "# show the best HD\n",
    "print(\"original_models valiation : \" + f'HD95 = {index_mean_hd95:.4f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 29.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSC = 0.5176906147485988, HD95 = 43.016026804543515\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "model_t1.eval()\n",
    "model_s.eval()\n",
    "for batch in tqdm(test_loader):\n",
    "    image_test, label, id_test = batch\n",
    "    image_test, label, id_test = image_test.to(device), label.to(device), id_test\n",
    "\n",
    "    H, W = label.size(1), label.size(2)\n",
    "    up_sizes = (ceil(H / 8) * 8, ceil(W / 8) * 8)\n",
    "\n",
    "    for i in range(0, int(label.size(0))):\n",
    "        folder_test = os.path.join(folder_name, \"test_target\")\n",
    "        os.makedirs(folder_test, exist_ok=True)\n",
    "        image = Image.fromarray(np.uint8(label[i].detach().cpu().numpy()))\n",
    "        image.save(os.path.join(folder_test, str(id_test[i]) + \".png\"))\n",
    "\n",
    "    data = torch.nn.functional.interpolate(image_test, size=(up_sizes[0], up_sizes[1]),\n",
    "                                            mode='bilinear', align_corners=True)\n",
    "    with torch.no_grad():\n",
    "        f = model_t1.encoder(data)\n",
    "        _, output = model_t1.decoder(f, data_shape=[data.shape[-2], data.shape[-1]])\n",
    "    output = torch.nn.functional.interpolate(output, size=(H, W),\n",
    "                                                mode='bilinear', align_corners=True)\n",
    "\n",
    "    for i in range(0, int(output.size(0))):\n",
    "        folder_test_prob = os.path.join(folder_name, \"test_original_models_prob\")\n",
    "        os.makedirs(folder_test_prob, exist_ok=True)\n",
    "        image_prob = output[i].squeeze().detach()\n",
    "        image_prob = torch.argmax(image_prob, dim=0).cpu().numpy()\n",
    "        image_prob = Image.fromarray((image_prob * 255).astype(np.uint8))\n",
    "        image_prob.save(os.path.join(folder_test_prob, str(id_test[i]) + \".png\"))\n",
    "\n",
    "    out = torch.argmax(torch.softmax(output, dim=1), dim=1).squeeze(0)\n",
    "    metric_i = test_single_volume(label, out, classes=2)\n",
    "    metric_list += np.array(metric_i)\n",
    "metric_list = metric_list / len(test_set)\n",
    "\n",
    "# performance = np.mean(metric_list, axis=0)[0]\n",
    "\n",
    "mean_hd95 = np.mean(metric_list, axis=0)[1]\n",
    "\n",
    "# show epoch mIoU, mDice\n",
    "index_mIoU, index_mDice = count_index(folder_test_prob, folder_test)\n",
    "\n",
    "\n",
    "print(f'DSC = {index_mDice}, HD95 = {mean_hd95}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps-mt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
