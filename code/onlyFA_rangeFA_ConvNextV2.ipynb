{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mutil Mean Teacher\n",
    "\n",
    "original\n",
    "FAICG_FA_FA\n",
    "\n",
    "backbone=DeeplabV3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import copy\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "from math import ceil\n",
    "from itertools import cycle\n",
    "from itertools import chain\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "batch_size = 7\n",
    "epochs = 80\n",
    "warm_up = 100\n",
    "labeled_examples = 515\n",
    "lr = 1e-2\n",
    "backbone = 101 #\" the resnet x {50, 101} layers\"\n",
    "semi_p_th = 0.6 # positive_threshold for semi-supervised loss\n",
    "semi_n_th = 0.0 # negative_threshold for semi-supervised loss\n",
    "unsup_weight = 1.5 # unsupervised weight for the semi-supervised loss\n",
    "\n",
    "config = json.load(open(\"configs/config_deeplab_v3+_onlyFA_range_selfsupervised.json\"))\n",
    "\n",
    "config['train_supervised']['batch_size'] = batch_size\n",
    "config['train_unsupervised']['batch_size'] = batch_size\n",
    "config['model']['epochs'] = epochs\n",
    "config['model']['warm_up_epoch'] = warm_up\n",
    "config['n_labeled_examples'] = labeled_examples\n",
    "config['model']['resnet'] = backbone\n",
    "config['optimizer']['args']['lr'] = lr\n",
    "config['unsupervised_w'] = unsup_weight\n",
    "config['model']['data_h_w'] = [config['train_supervised']['crop_size'], config['train_supervised']['crop_size']]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "logger = logging.getLogger(\"PS-MT\")\n",
    "logger.propagate = False\n",
    "logger.warning(\"Training start, 总共 {} epochs\".format(str(config['model']['epochs'])))\n",
    "logger.critical(\"GPUs: {}\".format(device))\n",
    "logger.critical(\"DeeplabV3+ with ResNet {} backbone\".format(str(config['model']['resnet'])))\n",
    "logger.critical(\"Current Labeled Example: {}\".format(config['n_labeled_examples']))\n",
    "logger.critical(\"Learning rate: other {}, and head is the SAME [world]\".format(config['optimizer']['args']['lr']))\n",
    "\n",
    "logger.critical(\"Current batch: {} [world]\".format(int(config['train_unsupervised']['batch_size']) +\n",
    "                                                int(config['train_supervised']['batch_size'])) )\n",
    "\n",
    "logger.critical(\"Current unsupervised loss function: {}, with weight {} and length {}\".format(config['model']['un_loss'],\n",
    "                                                                                            config['unsupervised_w'],\n",
    "                                                                                            config['ramp_up']))\n",
    "print(\"\\nconfig json :\")\n",
    "for i in config:\n",
    "    print(i, config[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA LOADERS\n",
    "from DataLoader.dataset_onlyFA import *\n",
    "choose_data = \"All\"\n",
    "\n",
    "config['train_supervised']['choose'] = choose_data\n",
    "config['train_unsupervised']['choose'] = choose_data\n",
    "config['val_loader']['choose'] = choose_data\n",
    "config['test_loader']['choose'] = choose_data\n",
    "\n",
    "print(\"train_supervised\")\n",
    "for i in config['train_supervised']:\n",
    "    print(\"    \",i, \":\", config['train_supervised'][i])\n",
    "print(\"train_unsupervised\")\n",
    "for i in config['train_unsupervised']:\n",
    "    print(\"    \", i, \":\", config['train_unsupervised'][i])\n",
    "print(\"val_loader\")\n",
    "for i in config['val_loader']:\n",
    "    print(\"    \", i, \":\", config['val_loader'][i])\n",
    "print(\"test_loader\")\n",
    "for i in config['test_loader']:\n",
    "    print(\"    \", i, \":\", config['test_loader'][i])\n",
    "\n",
    "supervised_set = BasicDataset(data_dir=config['train_supervised']['data_dir'], \n",
    "                                 choose=config['train_supervised']['choose'],\n",
    "                                 split=config['train_supervised']['split'])\n",
    "unsupervised_set = BasicDataset(data_dir=config['train_unsupervised']['data_dir'],\n",
    "                                   choose=config['train_unsupervised']['choose'],\n",
    "                                   split=config['train_unsupervised']['split'])\n",
    "val_set = BasicDataset(data_dir=config['val_loader']['data_dir'],\n",
    "                          choose=config['val_loader']['choose'],\n",
    "                          split=config['val_loader']['split'])\n",
    "\n",
    "test_set = BasicDataset(data_dir=config['test_loader']['data_dir'],\n",
    "                          choose=config['test_loader']['choose'],\n",
    "                          split=config['test_loader']['split'])\n",
    "\n",
    "self_supervised_set = BasicDataset(data_dir=config['train_unsupervised']['data_dir'],\n",
    "                                    choose=config['train_unsupervised']['choose'],\n",
    "                                    split=config['train_unsupervised']['split'])\n",
    "\n",
    "print(\"supervised_loader: \",len(supervised_set))\n",
    "print(\"unsupervised_loader: \",len(unsupervised_set))\n",
    "print(\"val_loader: \",len(val_set))\n",
    "print(\"test_loader: \",len(test_set))\n",
    "\n",
    "\n",
    "supervised_loader = DataLoader(dataset=supervised_set, batch_size=config['train_supervised']['batch_size'],\n",
    "                               shuffle=config['train_supervised']['shuffle'], \n",
    "                               num_workers=config['train_supervised']['num_workers'])\n",
    "unsupervised_loader = DataLoader(dataset=unsupervised_set, batch_size=config['train_unsupervised']['batch_size'],\n",
    "                               shuffle=config['train_unsupervised']['shuffle'], \n",
    "                               num_workers=config['train_unsupervised']['num_workers'])\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=config['val_loader']['batch_size'],\n",
    "                               shuffle=config['val_loader']['shuffle'], \n",
    "                               num_workers=config['val_loader']['num_workers'])\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=config['test_loader']['batch_size'],\n",
    "                               shuffle=config['test_loader']['shuffle'], \n",
    "                               num_workers=config['test_loader']['num_workers'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model setting (1 teacher + 1 student)\n",
    "from torch import optim\n",
    "\n",
    "from Model.Deeplabv3_plus.psmt_model import *\n",
    "from Utils.ramps import *\n",
    "\n",
    "cons_w_unsup = ConsistencyWeight(final_w=config['unsupervised_w'], iters_per_epoch=len(unsupervised_loader),\n",
    "                                 rampup_starts=0, rampup_ends=config['ramp_up'],  ramp_type=\"cosine_rampup\")\n",
    "\n",
    "\n",
    "model_t1 = Teacher_Net(num_classes=2, config=config['model'])\n",
    "model_t1 = model_t1.to(device)\n",
    "\n",
    "model_s = Student_Net(num_classes=2, config=config['model'],  cons_w_unsup=cons_w_unsup)\n",
    "model_s = model_s.to(device)\n",
    "\n",
    "optimizer_t1 = optim.SGD(model_t1.parameters(), \n",
    "                      lr=config['optimizer']['args']['lr'],\n",
    "                      momentum=config['optimizer']['args']['momentum'],\n",
    "                      weight_decay=config['optimizer']['args']['weight_decay'])\n",
    "\n",
    "optimizer_s = optim.SGD(model_s.parameters(), \n",
    "                      lr=config['optimizer']['args']['lr'],\n",
    "                      momentum=config['optimizer']['args']['momentum'],\n",
    "                      weight_decay=config['optimizer']['args']['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate metrics\n",
    "from sklearn import metrics, neighbors\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#compute mean IoU & DSC  of given outputs & targets per patient (5 time points)\n",
    "def information_index(outputs, targets):\n",
    "    eps = np.finfo(np.float64).eps\n",
    "    output = outputs.flatten()\n",
    "    target = targets.flatten()\n",
    "    TN, FP, FN, TP = confusion_matrix(target,output).ravel()\n",
    "\n",
    "    index_MIou =  ( TP / (TP + FP + FN + eps) + TN / (TN + FN + FP + eps) ) / 2\n",
    "    mean_iou = np.mean(index_MIou)\n",
    "    index_dice = 2*TP / (2*TP + FP + FN + eps)\n",
    "    mean_dice = np.mean(index_dice)\n",
    "\n",
    "    return mean_iou, mean_dice\n",
    "\n",
    "#compute mean IoU & DSC of validaton (test set)\n",
    "def count_index(pre, tar):\n",
    "        path_pre = pre\n",
    "        path_target = tar\n",
    "        dirs = os.listdir(path_pre)\n",
    "        # print(len(dirs))\n",
    "        con_mIOU = 0\n",
    "        con_mdice = 0\n",
    "        for imgs in dirs:\n",
    "            pre_path = path_pre + '/' + str(imgs)\n",
    "            target_path = path_target + '/' + str(imgs)\n",
    "\n",
    "            target = cv2.imread(target_path, cv2.IMREAD_GRAYSCALE)\n",
    "            _, tar = cv2.threshold(target, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            predict = cv2.imread(pre_path, cv2.IMREAD_GRAYSCALE)\n",
    "            _, pre = cv2.threshold(predict, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            tIOU, tdice = information_index(pre,tar)\n",
    "            con_mIOU += tIOU\n",
    "            con_mdice += tdice\n",
    "        val_mIoU = con_mIOU/len(dirs)\n",
    "        val_mDice = con_mdice/len(dirs)\n",
    "        \n",
    "        return val_mIoU, val_mDice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from medpy import metric\n",
    "# def calculate_metric_percase(pred, gt):\n",
    "#     pred[pred > 0] = 1\n",
    "#     gt[gt > 0] = 1\n",
    "#     if pred.sum() > 0:\n",
    "#         dice = metric.binary.dc(pred, gt)\n",
    "#         hd95 = metric.binary.hd95(pred, gt)\n",
    "#         return dice, hd95\n",
    "#     else:\n",
    "#         return 0, 0\n",
    "# def test_single_volume(label, output, classes=2):\n",
    "#     label = torch.clamp(label, 0, 1)\n",
    "#     label = label.squeeze(0).cpu().detach().numpy()\n",
    "#     output = output.cpu().detach().numpy()\n",
    "#     metric_list = []\n",
    "#     for i in range(1, classes):\n",
    "#         metric_list.append(calculate_metric_percase(\n",
    "#             output == i, label == i))\n",
    "    \n",
    "#     return metric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warm\n",
    "import torch.nn.functional\n",
    "from Utils.early_stop import EarlyStopping\n",
    "\n",
    "early_stopper = EarlyStopping(patience=5, delta=0.0001)\n",
    "\n",
    "for epoch in range(config['model']['warm_up_epoch']):\n",
    "\n",
    "    epoch_loss_t1 = 0\n",
    "    epoch_loss_s = 0\n",
    "    t1_mIoU, t1_mDice = 0, 0\n",
    "    s_mIoU, s_mDice = 0, 0\n",
    "    \n",
    "    localtime = time.asctime( time.localtime(time.time()) )\n",
    "    print('Epoch: {}/{} --- < Starting Time : {} >'.format(epoch + 1,config['model']['warm_up_epoch'],localtime))\n",
    "    print('-' * len('Epoch: {}/{} --- < Starting Time : {} >'.format(epoch + 1,config['model']['warm_up_epoch'],localtime)))\n",
    "\n",
    "    folder_name = None\n",
    "    folder_name = os.path.join(\"see_image\", \"self-warm\")\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    for batch in tqdm(unsupervised_loader):\n",
    "        input_ul, target_ul, id_ul = batch\n",
    "        input_ul, target_ul, id_ul = input_ul.to(device), target_ul.to(device), id_ul\n",
    "\n",
    "        for i in range(0, int(input_ul.size(0))):\n",
    "            folder_target = os.path.join(folder_name, \"target\")\n",
    "            os.makedirs(folder_target, exist_ok=True)\n",
    "#           image = input_ul[i].squeeze().detach()\n",
    "#           image = torch.argmax(image, dim=0).cpu().numpy()\n",
    "            image = input_ul[i].detach().cpu().numpy().transpose(1,2,0)\n",
    "            image = np.clip(image * 255, 0, 255)\n",
    "            image = Image.fromarray(image.astype(np.uint8))\n",
    "            image.save(os.path.join(folder_target, str(id_ul[i]) + \".png\"))\n",
    "\n",
    "        # warm teacher\n",
    "        model_t1.train()\n",
    "        model_s.eval()\n",
    "        optimizer_t1.zero_grad()\n",
    "        loss_t1, outputs = model_t1(input_ul=input_ul, target_ul=input_ul, warm_up=True, mix_up=False)\n",
    "        output_t1 = outputs[\"self_pred\"]\n",
    "        \n",
    "\n",
    "        for i in range(0, int(output_t1.size(0))):\n",
    "            folder_t1_prob = os.path.join(folder_name, \"t1_prob\")\n",
    "            os.makedirs(folder_t1_prob, exist_ok=True)\n",
    "#           image_prob = output_t1[i].squeeze().detach()\n",
    "#           image_prob = torch.argmax(image_prob, dim=0).cpu().numpy()\n",
    "            image_prob = output_t1[i].detach().cpu().numpy().transpose(1,2, 0)         \n",
    "            image_prob = np.clip(image_prob * 255, 0, 255)\n",
    "            image_prob = Image.fromarray(image_prob.astype(np.uint8))\n",
    "            image_prob.save(os.path.join(folder_t1_prob, str(id_ul[i]) + \".png\"))\n",
    "\n",
    "\n",
    "        epoch_loss_t1 += loss_t1\n",
    "        loss_t1.backward()\n",
    "        optimizer_t1.step()\n",
    "        \n",
    "        # warm student\n",
    "        model_t1.eval()\n",
    "        model_s.train()\n",
    "        optimizer_s.zero_grad()\n",
    "        loss_s, outputs = model_s(x_ul=input_ul, warm_up=True, mix_up=False)\n",
    "        output_s = outputs[\"self_pred\"]\n",
    "        \n",
    "        for i in range(0, int(output_s.size(0))):\n",
    "            folder_s_prob = os.path.join(folder_name, \"s_prob\")\n",
    "            os.makedirs(folder_s_prob, exist_ok=True)\n",
    "#           image_prob = output_s[i].squeeze().detach()\n",
    "#           image_prob = torch.argmax(image_prob, dim=0).cpu().numpy()\n",
    "            image_prob = output_s[i].detach().cpu().numpy().transpose(1, 2, 0)                           \n",
    "            image_prob = np.clip(image_prob * 255, 0, 255)\n",
    "            image_prob = Image.fromarray(image_prob.astype(np.uint8))\n",
    "            image_prob.save(os.path.join(folder_s_prob, str(id_ul[i]) + \".png\"))\n",
    "\n",
    "        epoch_loss_s += loss_s\n",
    "        loss_s.backward()\n",
    "        optimizer_s.step()\n",
    "\n",
    "    t1_mIoU, t1_mDice = count_index(folder_t1_prob, folder_target)\n",
    "    s_mIoU, s_mDice = count_index(folder_s_prob, folder_target)\n",
    "\n",
    "    print(f'Epoch{epoch+1} loss : \\nteacher 1 loss = {epoch_loss_t1/len(supervised_set)},student loss = {epoch_loss_s/len(supervised_set)}') \n",
    "    print(f'teacher 1 dsc loss = {t1_mDice}, sutdent dsc loss = {s_mDice}')\n",
    "\n",
    "\n",
    "    if s_mDice > 0.95:\n",
    "        early_stopper(epoch_loss_s/len(supervised_set))\n",
    "        print(f'teacher 1 : mIoU = {t1_mIoU}, DCS = {t1_mDice}')\n",
    "        print(f'student : mIoU = {s_mIoU}, DCS = {s_mDice}')\n",
    "        if early_stopper.early_stop: \n",
    "            print(\"Early stopping\")   \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_teachers_parameters(model):\n",
    "    for p in model.encoder.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in model.decoder.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "freeze_teachers_parameters(model_t1)\n",
    "\n",
    "def update_teachers(teacher, student, keep_rate=0.996):\n",
    "    student_encoder_dict = student.encoder.state_dict()\n",
    "    student_decoder_dict = student.decoder.state_dict()\n",
    "    new_teacher_encoder_dict = OrderedDict()\n",
    "    new_teacher_decoder_dict = OrderedDict()\n",
    "\n",
    "    for key, value in teacher.encoder.state_dict().items():\n",
    "\n",
    "        if key in student_encoder_dict.keys():\n",
    "            new_teacher_encoder_dict[key] = (\n",
    "                    student_encoder_dict[key] * (1 - keep_rate) + value * keep_rate\n",
    "            )\n",
    "        else:\n",
    "            raise Exception(\"{} is not found in student encoder model\".format(key))\n",
    "\n",
    "    for key, value in teacher.decoder.state_dict().items():\n",
    "\n",
    "        if key in student_decoder_dict.keys():\n",
    "            new_teacher_decoder_dict[key] = (\n",
    "                    student_decoder_dict[key] * (1 - keep_rate) + value * keep_rate\n",
    "            )\n",
    "        else:\n",
    "            raise Exception(\"{} is not found in student decoder model\".format(key))\n",
    "    teacher.encoder.load_state_dict(new_teacher_encoder_dict, strict=True)\n",
    "    teacher.decoder.load_state_dict(new_teacher_decoder_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_out_grad(model_t1, model_t2, image):\n",
    "    with torch.no_grad():\n",
    "        f = model_t1.encoder(image)\n",
    "        _, predict_target_ul1 = model_t1.decoder(f, data_shape=[image.shape[-2], image.shape[-1]])\n",
    "        f = model_t2.encoder(image)\n",
    "        _, predict_target_ul2 = model_t2.decoder(f, data_shape=[image.shape[-2], image.shape[-1]])\n",
    "        \n",
    "        predict_target_ul1 = torch.nn.functional.interpolate(predict_target_ul1,\n",
    "                                                                size=(image.shape[-2], image.shape[-1]),\n",
    "                                                                mode='bilinear',\n",
    "                                                                align_corners=True)\n",
    "\n",
    "        predict_target_ul2 = torch.nn.functional.interpolate(predict_target_ul2,\n",
    "                                                                size=(image.shape[-2], image.shape[-1]),\n",
    "                                                                mode='bilinear',\n",
    "                                                                align_corners=True)\n",
    "\n",
    "        assert predict_target_ul1.shape == predict_target_ul2.shape, \"Expect two prediction in same shape,\"\n",
    "    return predict_target_ul1, predict_target_ul2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi train\n",
    "from Utils.early_stop import EarlyStopper\n",
    "\n",
    "early_stopper = EarlyStopper(patience=5, delta=0.001)\n",
    "\n",
    "best_model_t1_params = copy.deepcopy(model_t1.state_dict())\n",
    "best_model_s_params = copy.deepcopy(model_s.state_dict())\n",
    "do_best_Dice = 0\n",
    "do_best_mIoU = 0\n",
    "# do_best_hd95 = 100000\n",
    "do_best_epoch = 0\n",
    "\n",
    "for epoch in range(config['model']['epochs']):\n",
    "\n",
    "    model_s.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_dsc = 0\n",
    "\n",
    "    dataloader = iter(zip(cycle(supervised_loader), unsupervised_loader))\n",
    "\n",
    "    localtime = time.asctime( time.localtime(time.time()) )\n",
    "    print('Epoch: {}/{} --- < Starting Time : {} >'.format(epoch + 1,config['model']['epochs'],localtime))\n",
    "    print('-' * len('Epoch: {}/{} --- < Starting Time : {} >'.format(epoch + 1,config['model']['epochs'],localtime)))\n",
    "\n",
    "    tbar = tqdm(range(len(unsupervised_loader)))\n",
    "    for batch_idx in tbar:\n",
    "        (image_FA, image_ICG, target_l, id_l), (input_ul, target_ul, id_ul) = next(dataloader)\n",
    "        image_FA, image_ICG, target_l, id_l = image_FA.to(device), image_ICG.to(device), target_l.to(device), id_l\n",
    "        input_ul, target_ul, id_ul = input_ul.to(device), target_ul.to(device), id_ul\n",
    "        print(input_ul.shape)\n",
    "        optimizer_s.zero_grad()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            f = model_t1.encoder(input_ul)\n",
    "            _, predict_target_ul1 = model_t1.decoder(f, data_shape=[input_ul.shape[-2], input_ul.shape[-1]])\n",
    "            \n",
    "            predict_target_ul1 = torch.nn.functional.interpolate(predict_target_ul1,\n",
    "                                                                    size=(input_ul.shape[-2], input_ul.shape[-1]),\n",
    "                                                                    mode='bilinear',\n",
    "                                                                    align_corners=True)\n",
    "\n",
    "        total_loss, cur_losses, outputs = model_s(x_FA=image_FA, x_ICG=image_ICG, target_l=target_l,\n",
    "                                                  x_ul=input_ul, target_ul=predict_target_ul1,\n",
    "                                                  epoch=epoch, curr_iter=batch_idx, warm_up=False,\n",
    "                                                  mix_up=False, t1=model_t1, t2=model_t1)\n",
    "        \n",
    "        epoch_loss += total_loss\n",
    "        total_loss.backward()\n",
    "        optimizer_s.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            update_teachers(teacher=model_t1,\n",
    "                            student=model_s)\n",
    "\n",
    "    # validation\n",
    "    # metric_list = 0.0\n",
    "    model_s.eval()\n",
    "    for batch in tqdm(val_loader):\n",
    "        image_val, label, id_val = batch\n",
    "        image_val, label, id_val = image_val.to(device), label.to(device), id_val\n",
    "\n",
    "        H, W = label.size(1), label.size(2)\n",
    "        up_sizes = (ceil(H / 8) * 8, ceil(W / 8) * 8)\n",
    "\n",
    "        for i in range(0, int(label.size(0))):\n",
    "            folder_val = os.path.join(folder_name, \"val_original_target\")\n",
    "            os.makedirs(folder_val, exist_ok=True)\n",
    "            image = Image.fromarray(np.uint8(label[i].detach().cpu().numpy()))\n",
    "            image.save(os.path.join(folder_val, str(id_val[i]) + \".png\"))\n",
    "\n",
    "        data = torch.nn.functional.interpolate(image_val, size=(up_sizes[0], up_sizes[1]),\n",
    "                                               mode='bilinear', align_corners=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            f = model_t1.encoder(data)\n",
    "            _, output = model_t1.decoder(f, data_shape=[data.shape[-2], data.shape[-1]])\n",
    "        output = torch.nn.functional.interpolate(output, size=(H, W),\n",
    "                                                 mode='bilinear', align_corners=True)\n",
    "\n",
    "        for i in range(0, int(output.size(0))):\n",
    "            folder_val_prob = os.path.join(folder_name, \"val_original_prob\")\n",
    "            os.makedirs(folder_val_prob, exist_ok=True)\n",
    "            image_prob = output[i].squeeze().detach()\n",
    "            image_prob = torch.argmax(image_prob, dim=0).cpu().numpy()\n",
    "            image_prob = Image.fromarray((image_prob * 255).astype(np.uint8))\n",
    "            image_prob.save(os.path.join(folder_val_prob, str(id_val[i]) + \".png\"))\n",
    "        \n",
    "    #     out = torch.argmax(torch.softmax(output, dim=1), dim=1).squeeze(0)\n",
    "    #     metric_i = test_single_volume(label, out, classes=2)\n",
    "    #     metric_list += np.array(metric_i)\n",
    "    # metric_list = metric_list / len(val_set)\n",
    "    # # index_mDice = np.mean(metric_list, axis=0)[0]\n",
    "    # index_mean_hd95 = np.mean(metric_list, axis=0)[1]\n",
    "    \n",
    "    # show epoch mIoU, mDice\n",
    "    index_mIoU, index_mDice = count_index(folder_val_prob, folder_val)\n",
    "    # print(f'Epoch {epoch+1}' + \" val:\" + f'DSC: {index_mDice:.4f}, HD95 = {index_mean_hd95:.4f}')\n",
    "    print(f'Epoch {epoch+1}' + \" val:\" + f'mIoU: {index_mIoU:.4f}, DSC: {index_mDice:.4f}')\n",
    "\n",
    "    # find the best mIoU, mDice\n",
    "    # if index_mDice > do_best_Dice and (index_mDice > do_best_Dice or index_mean_hd95 < do_best_hd95):\n",
    "    if index_mDice > do_best_Dice:\n",
    "        early_stopper.best_score = index_mDice\n",
    "        early_stopper.counter = 0\n",
    "        do_best_Dice = index_mDice\n",
    "        do_best_mIoU = index_mIoU\n",
    "        # do_best_hd95 = index_mean_hd95\n",
    "        do_best_epoch = epoch+1\n",
    "        best_model_t1_params = copy.deepcopy(model_t1.state_dict())\n",
    "        best_model_s_params = copy.deepcopy(model_s.state_dict())\n",
    "        # print(\"Change Best: \" + f'epoch: {do_best_epoch} DSC: {do_best_Dice:.4f}, HD95 = {do_best_hd95:.4f}')\n",
    "        print(\"Change Best: \" + f'epoch : {do_best_epoch} mIoU: {do_best_mIoU:.4f}, DSC: {do_best_Dice:.4f}')\n",
    "\n",
    "        # save the best valiation prod\n",
    "        folder_val_best_prob = os.path.join(folder_name, \"val_original_best_prob\")\n",
    "        os.makedirs(folder_val_best_prob, exist_ok=True)\n",
    "        file_names = os.listdir(folder_val_prob)\n",
    "        for file_name in file_names:\n",
    "            source_path = os.path.join(folder_val_prob, file_name)\n",
    "            destination_path = os.path.join(folder_val_best_prob, file_name)\n",
    "            shutil.copyfile(source_path, destination_path)\n",
    "    else:\n",
    "        if epoch >= 5:\n",
    "            early_stopper(index_mDice)\n",
    "    \n",
    "    if early_stopper.early_stop: \n",
    "        print(\"Early stopping\")   \n",
    "        break\n",
    "\n",
    "    # show the best mIoU, mDice\n",
    "    # print(\"Best model : \" + f'epoch : {do_best_epoch}  DSC : {do_best_Dice:.4f}, HD95 = {do_best_hd95:.4f}')\n",
    "    print(\"Best model : \" + f'epoch : {do_best_epoch} mIoU: {do_best_mIoU:.4f}, DSC: {do_best_Dice:.4f}')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best teacher1&2 and student model\n",
    "model_path = None\n",
    "model_path = os.path.join(\"saved_models\")\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "model_params = os.path.join(model_path, \"original_models\")\n",
    "os.makedirs(model_params, exist_ok=True)\n",
    "\n",
    "torch.save(best_model_t1_params, os.path.join(model_params, f'original_epoch_{do_best_epoch}_dsc_{do_best_Dice:.4f}_best_t1.pth'))\n",
    "torch.save(best_model_s_params, os.path.join(model_params, f'original_epoch_{do_best_epoch}_dsc_{do_best_Dice:.4f}_best_s.pth'))\n",
    "print(\"Best model : \" + f'epoch : {do_best_epoch}  DSC : {do_best_Dice:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps-mt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
