{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import copy\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "from math import ceil\n",
    "from itertools import cycle\n",
    "from itertools import chain\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "batch_size = 8\n",
    "epochs = 80\n",
    "warm_up = 100\n",
    "labeled_examples = 515\n",
    "lr = 1e-2\n",
    "backbone = 101 #\" the resnet x {50, 101} layers\"\n",
    "semi_p_th = 0.6 # positive_threshold for semi-supervised loss\n",
    "semi_n_th = 0.0 # negative_threshold for semi-supervised loss\n",
    "unsup_weight = 1.5 # unsupervised weight for the semi-supervised loss\n",
    "\n",
    "config = json.load(open(\"configs/config_deeplab_v3+_onlyFA_range.json\"))\n",
    "\n",
    "config['train_supervised']['batch_size'] = batch_size\n",
    "config['train_unsupervised']['batch_size'] = batch_size\n",
    "config['warm_selfsupervised']['batch_size'] = batch_size\n",
    "config['model']['epochs'] = epochs\n",
    "config['model']['warm_up_epoch'] = warm_up\n",
    "config['n_labeled_examples'] = labeled_examples\n",
    "config['model']['resnet'] = backbone\n",
    "config['optimizer']['args']['lr'] = lr\n",
    "config['unsupervised_w'] = unsup_weight\n",
    "config['model']['data_h_w'] = [config['train_supervised']['crop_size'], config['train_supervised']['crop_size']]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "logger = logging.getLogger(\"PS-MT\")\n",
    "logger.propagate = False\n",
    "logger.warning(\"Training start, 总共 {} epochs\".format(str(config['model']['epochs'])))\n",
    "logger.critical(\"GPUs: {}\".format(device))\n",
    "logger.critical(\"DeeplabV3+ with ResNet {} backbone\".format(str(config['model']['resnet'])))\n",
    "logger.critical(\"Current Labeled Example: {}\".format(config['n_labeled_examples']))\n",
    "logger.critical(\"Learning rate: other {}, and head is the SAME [world]\".format(config['optimizer']['args']['lr']))\n",
    "\n",
    "logger.critical(\"Current batch: {} [world]\".format(int(config['train_unsupervised']['batch_size']) +\n",
    "                                                int(config['train_supervised']['batch_size'])) )\n",
    "\n",
    "logger.critical(\"Current unsupervised loss function: {}, with weight {} and length {}\".format(config['model']['un_loss'],\n",
    "                                                                                            config['unsupervised_w'],\n",
    "                                                                                            config['ramp_up']))\n",
    "print(\"\\nconfig json :\")\n",
    "for i in config:\n",
    "    print(i, config[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA LOADERS\n",
    "from DataLoader.dataset_onlyFA import *\n",
    "choose_data = \"All\"\n",
    "\n",
    "config['train_supervised']['choose'] = choose_data\n",
    "config['train_unsupervised']['choose'] = choose_data\n",
    "config['warm_selfsupervised']['choose'] = choose_data\n",
    "config['val_loader']['choose'] = choose_data\n",
    "config['test_loader']['choose'] = choose_data\n",
    "\n",
    "print(\"train_supervised\")\n",
    "for i in config['train_supervised']:\n",
    "    print(\"    \",i, \":\", config['train_supervised'][i])\n",
    "print(\"train_unsupervised\")\n",
    "for i in config['train_unsupervised']:\n",
    "    print(\"    \", i, \":\", config['train_unsupervised'][i])\n",
    "print(\"warm_selfsupervised\")\n",
    "for i in config['warm_selfsupervised']:\n",
    "    print(\"    \", i, \":\", config['warm_selfsupervised'][i])\n",
    "print(\"val_loader\")\n",
    "for i in config['val_loader']:\n",
    "    print(\"    \", i, \":\", config['val_loader'][i])\n",
    "print(\"test_loader\")\n",
    "for i in config['test_loader']:\n",
    "    print(\"    \", i, \":\", config['test_loader'][i])\n",
    "\n",
    "supervised_set = BasicDataset(data_dir=config['train_supervised']['data_dir'], \n",
    "                                 choose=config['train_supervised']['choose'],\n",
    "                                 split=config['train_supervised']['split'])\n",
    "\n",
    "unsupervised_set = BasicDataset(data_dir=config['train_unsupervised']['data_dir'],\n",
    "                                   choose=config['train_unsupervised']['choose'],\n",
    "                                   split=config['train_unsupervised']['split'])\n",
    "\n",
    "warm_selfsupervised_set = BasicDataset(data_dir=config['warm_selfsupervised']['data_dir'],\n",
    "                                       choose=config['warm_selfsupervised']['choose'],\n",
    "                                       split=config['warm_selfsupervised']['split'])\n",
    "\n",
    "val_set = BasicDataset(data_dir=config['val_loader']['data_dir'],\n",
    "                          choose=config['val_loader']['choose'],\n",
    "                          split=config['val_loader']['split'])\n",
    "\n",
    "test_set = BasicDataset(data_dir=config['test_loader']['data_dir'],\n",
    "                          choose=config['test_loader']['choose'],\n",
    "                          split=config['test_loader']['split'])\n",
    "\n",
    "print(\"supervised_loader: \",len(supervised_set))\n",
    "print(\"unsupervised_loader: \",len(unsupervised_set))\n",
    "print(\"warm_selfsupervised_loader: \",len(warm_selfsupervised_set))\n",
    "print(\"val_loader: \",len(val_set))\n",
    "print(\"test_loader: \",len(test_set))\n",
    "\n",
    "\n",
    "supervised_loader = DataLoader(dataset=supervised_set, batch_size=config['train_supervised']['batch_size'],\n",
    "                               shuffle=config['train_supervised']['shuffle'], \n",
    "                               num_workers=config['train_supervised']['num_workers'])\n",
    "\n",
    "unsupervised_loader = DataLoader(dataset=unsupervised_set, batch_size=config['train_unsupervised']['batch_size'],\n",
    "                               shuffle=config['train_unsupervised']['shuffle'], \n",
    "                               num_workers=config['train_unsupervised']['num_workers'])\n",
    "                               \n",
    "warm_selfsupervised_loader = DataLoader(dataset=warm_selfsupervised_set, batch_size=config['train_warm_selfsupervised']['batch_size'],\n",
    "                               shuffle=config['train_warm_selfsupervised']['shuffle'],\n",
    "                               num_workers=config['train_warm_selfsupervised']['num_workers'])\n",
    "\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=config['val_loader']['batch_size'],\n",
    "                               shuffle=config['val_loader']['shuffle'], \n",
    "                               num_workers=config['val_loader']['num_workers'])\n",
    "\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=config['test_loader']['batch_size'],\n",
    "                               shuffle=config['test_loader']['shuffle'], \n",
    "                               num_workers=config['test_loader']['num_workers'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate metrics \n",
    "\n",
    "from sklearn import metrics, neighbors\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#calculate mean IoU & mean DSC of given outputs & targets\n",
    "def information_index(outputs, targets):\n",
    "    eps = np.finfo(np.float64).eps\n",
    "    output = outputs.flatten()\n",
    "    target = targets.flatten()\n",
    "    TN, FP, FN, TP = confusion_matrix(target,output).ravel()\n",
    "\n",
    "    index_MIou =  ( TP / (TP + FP + FN + eps) + TN / (TN + FN + FP + eps) ) / 2\n",
    "    mean_iou = np.mean(index_MIou)\n",
    "    index_dice = 2*TP / (2*TP + FP + FN + eps)\n",
    "    mean_dice = np.mean(index_dice)\n",
    "\n",
    "    return mean_iou, mean_dice\n",
    "\n",
    "#calculate mean IoU & mean DSC of validation (test set)\n",
    "def count_index(pre, tar):\n",
    "        path_pre = pre\n",
    "        path_target = tar\n",
    "        dirs = os.listdir(path_pre)\n",
    "        # print(len(dirs))\n",
    "        con_mIOU = 0\n",
    "        con_mdice = 0\n",
    "        for imgs in dirs:\n",
    "            pre_path = path_pre + '/' + str(imgs)\n",
    "            target_path = path_target + '/' + str(imgs)\n",
    "\n",
    "            target = cv2.imread(target_path, cv2.IMREAD_GRAYSCALE)\n",
    "            _, tar = cv2.threshold(target, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            predict = cv2.imread(pre_path, cv2.IMREAD_GRAYSCALE)\n",
    "            _, pre = cv2.threshold(predict, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            tIOU, tdice = information_index(pre,tar)\n",
    "            con_mIOU += tIOU\n",
    "            con_mdice += tdice\n",
    "        val_mIoU = con_mIOU/len(dirs)\n",
    "        val_mDice = con_mdice/len(dirs)\n",
    "        \n",
    "        return val_mIoU, val_mDice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate DSC & HD\n",
    "\n",
    "from medpy import metric\n",
    "\n",
    "#calculate DSC & HD of each image\n",
    "def calculate_metric_percase(pred, gt):\n",
    "    pred[pred > 0] = 1\n",
    "    gt[gt > 0] = 1\n",
    "    if pred.sum() > 0:\n",
    "        dice = metric.binary.dc(pred, gt)\n",
    "        hd95 = metric.binary.hd95(pred, gt)\n",
    "        return dice, hd95\n",
    "    else:\n",
    "        return 0, 0\n",
    "\n",
    "#append DSC & HD of each patient (5 time points)\n",
    "def test_single_volume(label, output, classes=2):\n",
    "    label = torch.clamp(label, 0, 1)\n",
    "    label = label.squeeze(0).cpu().detach().numpy()\n",
    "    output = output.cpu().detach().numpy()\n",
    "    metric_list = []\n",
    "    for i in range(1, classes):\n",
    "        metric_list.append(calculate_metric_percase(\n",
    "            output == i, label == i))\n",
    "    \n",
    "    return metric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model setting (1 teacher + 1 student)\n",
    "from torch import optim\n",
    "\n",
    "from Model.selfsupervised.selfsupervised_model import *\n",
    "from Utils.ramps import *\n",
    "\n",
    "cons_w_unsup = ConsistencyWeight(final_w=config['unsupervised_w'], iters_per_epoch=len(unsupervised_loader),\n",
    "                                 rampup_starts=0, rampup_ends=config['ramp_up'],  ramp_type=\"cosine_rampup\")\n",
    "\n",
    "\n",
    "model_t1 = Teacher_Net(num_classes=2, config=config['model'])\n",
    "model_t1 = model_t1.to(device)\n",
    "\n",
    "model_s = Student_Net(num_classes=2, config=config['model'],  cons_w_unsup=cons_w_unsup)\n",
    "model_s = model_s.to(device)\n",
    "\n",
    "optimizer_t1 = optim.SGD(model_t1.parameters(), \n",
    "                      lr=config['optimizer']['args']['lr'],\n",
    "                      momentum=config['optimizer']['args']['momentum'],\n",
    "                      weight_decay=config['optimizer']['args']['weight_decay'])\n",
    "\n",
    "optimizer_s = optim.SGD(model_s.parameters(), \n",
    "                      lr=config['optimizer']['args']['lr'],\n",
    "                      momentum=config['optimizer']['args']['momentum'],\n",
    "                      weight_decay=config['optimizer']['args']['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val HD\n",
    "\n",
    "PRED_MODEL_t1 = './saved_models/onlyFA_rangeFA/original_models/original_epoch_3_dsc_0.5765_best_t1.pth'\n",
    "PRED_MODEL_s = './saved_models//onlyFA_rangeFA/original_models/original_epoch_3_dsc_0.5765_best_s.pth'\n",
    "\n",
    "model_t1.load_state_dict(torch.load(PRED_MODEL_t1, map_location=device))\n",
    "model_s.load_state_dict(torch.load(PRED_MODEL_s, map_location=device))\n",
    "\n",
    "folder_name = None\n",
    "folder_name = os.path.join(\"see_image\")\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# validation\n",
    "metric_list = 0.0\n",
    "list = []\n",
    "model_t1.eval()\n",
    "model_s.eval()\n",
    "for batch in tqdm(val_loader):\n",
    "    image_val, label, id_val = batch\n",
    "    image_val, label, id_val = image_val.to(device), label.to(device), id_val\n",
    "\n",
    "    H, W = label.size(1), label.size(2)\n",
    "    up_sizes = (ceil(H / 8) * 8, ceil(W / 8) * 8)\n",
    "    data = torch.nn.functional.interpolate(image_val, size=(up_sizes[0], up_sizes[1]),\n",
    "                                            mode='bilinear', align_corners=True)\n",
    "    with torch.no_grad():\n",
    "        loss_t1, output = model_t1(input_ul=data, target_ul=label)\n",
    "    output = torch.nn.functional.interpolate(output, size=(H, W),\n",
    "                                                mode='bilinear', align_corners=True)\n",
    "    \n",
    "    out = torch.argmax(torch.softmax(output, dim=1), dim=1).squeeze(0)\n",
    "    metric_i = test_single_volume(label, out, classes=2)\n",
    "    list.append(metric_i[0][1])\n",
    "    metric_list += np.array(metric_i)\n",
    "metric_list = metric_list / len(val_set)\n",
    "print(list)\n",
    "# index_mDice = np.mean(metric_list, axis=0)[0]\n",
    "index_mean_hd95 = np.mean(metric_list, axis=0)[1]\n",
    "\n",
    "\n",
    "\n",
    "# show the best HD\n",
    "print(\"original_models valiation : \" + f'HD95 = {index_mean_hd95:.4f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "model_t1.eval()\n",
    "model_s.eval()\n",
    "for batch in tqdm(test_loader):\n",
    "    image_test, label, id_test = batch\n",
    "    image_test, label, id_test = image_test.to(device), label.to(device), id_test\n",
    "\n",
    "    H, W = label.size(1), label.size(2)\n",
    "    up_sizes = (ceil(H / 8) * 8, ceil(W / 8) * 8)\n",
    "\n",
    "    for i in range(0, int(label.size(0))):\n",
    "        folder_test = os.path.join(folder_name, \"test_target\")\n",
    "        os.makedirs(folder_test, exist_ok=True)\n",
    "        image = Image.fromarray(np.uint8(label[i].detach().cpu().numpy()))\n",
    "        image.save(os.path.join(folder_test, str(id_test[i]) + \".png\"))\n",
    "\n",
    "    data = torch.nn.functional.interpolate(image_test, size=(up_sizes[0], up_sizes[1]),\n",
    "                                            mode='bilinear', align_corners=True)\n",
    "    with torch.no_grad():\n",
    "        f = model_t1.encoder(data)\n",
    "        _, output = model_t1.decoder(f, data_shape=[data.shape[-2], data.shape[-1]])\n",
    "    output = torch.nn.functional.interpolate(output, size=(H, W),\n",
    "                                                mode='bilinear', align_corners=True)\n",
    "\n",
    "    for i in range(0, int(output.size(0))):\n",
    "        folder_test_prob = os.path.join(folder_name, \"test_original_models_prob\")\n",
    "        os.makedirs(folder_test_prob, exist_ok=True)\n",
    "        image_prob = output[i].squeeze().detach()\n",
    "        image_prob = torch.argmax(image_prob, dim=0).cpu().numpy()\n",
    "        image_prob = Image.fromarray((image_prob * 255).astype(np.uint8))\n",
    "        image_prob.save(os.path.join(folder_test_prob, str(id_test[i]) + \".png\"))\n",
    "\n",
    "    out = torch.argmax(torch.softmax(output, dim=1), dim=1).squeeze(0)\n",
    "    metric_i = test_single_volume(label, out, classes=2)\n",
    "    metric_list += np.array(metric_i)\n",
    "metric_list = metric_list / len(test_set)\n",
    "\n",
    "# performance = np.mean(metric_list, axis=0)[0]\n",
    "\n",
    "mean_hd95 = np.mean(metric_list, axis=0)[1]\n",
    "\n",
    "# show epoch mIoU, mDice\n",
    "index_mIoU, index_mDice = count_index(folder_test_prob, folder_test)\n",
    "\n",
    "\n",
    "print(f'DSC = {index_mDice}, HD95 = {mean_hd95}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
